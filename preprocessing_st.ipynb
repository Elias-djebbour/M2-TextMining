{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\bapti\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bapti\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\bapti\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\bapti\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          clean_text\n",
      "0  photo josh riemer unsplash merry christmas hap...\n",
      "1  brain coronavirus guide curious troubling impa...\n",
      "2  mind nose smell training change brain six week...\n",
      "3  passionate synergy science technology provide ...\n",
      "4  youve heard havent phineas gage railroad worke...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "path = \"./archive/medium_articles.csv\"\n",
    "\n",
    "df = pd.read_csv(path, delimiter=\",\", quotechar='\"')\n",
    "\n",
    "# Télécharger les ressources nécessaires\n",
    "nltk.download('punkt')  # Pour la tokenisation (word_tokenize)\n",
    "nltk.download('stopwords')  # Pour les stopwords\n",
    "nltk.download('wordnet')  # Pour la lemmatisation (WordNetLemmatizer)\n",
    "nltk.download('averaged_perceptron_tagger')  # Optionnel, pour la lemmatisation avancée\n",
    "\n",
    "nltk.data.path.append('C:/Users/scien/AppData/Roaming/nltk_data')\n",
    "\n",
    "# Initialisation des outils de NLP\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if isinstance(text, str):  # Vérifie que la valeur est bien une chaîne de caractères\n",
    "        # 1️⃣ Suppression de la ponctuation et des balises HTML\n",
    "        text = re.sub(r'<.*?>', '', text)  # Enlever les balises HTML\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Garde uniquement les lettres et espaces\n",
    "\n",
    "        # 2️⃣ Mise en minuscules\n",
    "        text = text.lower()\n",
    "\n",
    "        # 3️⃣ Tokenization\n",
    "        tokens = word_tokenize(text)\n",
    "\n",
    "        # 4️⃣ Suppression des stopwords\n",
    "        tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "        # 5️⃣ Stemming\n",
    "        #tokens = [stemmer.stem(word) for word in tokens]\n",
    "\n",
    "        # 6️⃣ Lemmatisation\n",
    "        tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "        return ' '.join(tokens)  # Reconstruction du texte\n",
    "    return text  # Retourne tel quel si ce n'est pas une string\n",
    "\n",
    "# Appliquer le prétraitement sur la colonne \"text\"\n",
    "df['clean_text'] = df['text'].apply(preprocess_text)\n",
    "\n",
    "# Afficher un échantillon des textes nettoyés\n",
    "print(df[['clean_text']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde du nouveau dataset avec la colonne 'clean_text'\n",
    "df.to_csv(\"./archive/lemmetised_clean_data.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
